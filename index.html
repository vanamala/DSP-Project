<html>
	<head>
		<style type="text/css">
			body{font-family: "Bradley Hand ITC";}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 36px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 15px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 24px;font-weight: bold;}
			.text{width: 95%;font-size: 20px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 20px;}
			.image{width: 95%;font-size: 20px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title">Activity Detection using Accelerometer Data</div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>Harsh Bhardwaj, Roll No.: 150102023, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Shubham Lohiya, Roll No.: 150102064, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Aniruddha Ghosh, Roll No.: 150102078, Branch: ECE</p>; &nbsp; &nbsp;
				<p>Bhargav Vanamala, Roll No.: 150102082, Branch: ECE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">

					<!-- Start edit here  -->
					Activity Recognition is an emerging field of research, born from the larger fields of ubiquitous computing, context-aware computing and multimedia. Recently, recognizing everyday life activities becomes
					one of the challenges for pervasive computing.
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					 When we watch a person, it is easy for us to tell what activity they are performing even if we have never seen them in the past. This is because our brains are already trained to understand human activities. When viewing the activity, the brain compares it to thousands of activities it has memorized and pops out the one that matches. Similarly, a computer can identify the activity one is performing based on activities we have trained it to identify. <br>
					 On a computer, a machine learning algorithm can be used to “learn” human activities and detect the activity being performed for the new data that is collected. A detection task such as this, which involves categorizing data into separate “classes” is called classification. Applying a classification algorithm to this task involves two steps: training and detection. The training step builds a model which maps training data to certain categories. The detection step maps new data to a category. <br>
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						We will be given accelerometer data from 3 activities namely: Standing, Running and Cycling and we need to classify/detect which activity is being performed, from those data entries.  
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  -->
						Block diagram of the system.
						<img src="Try.png" width="540px" height="360px" alt="This text displays when the image is unavailable"/>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						Classification of activities using an accelerometer data has been quite a challenging case. There is always a chance of wrong classification beacause of the noise that gets recorded along with the useful acceleration data. There was a need to extract those features out of the dataset which would be noise resistant.
						A successful technique for extracting features from sequential motion data has been demonstrated to be windowing with overlapping. From each window, we propose to extract the following features: root mean squared value of integration of acceleration in a window, mean value of Minmax sums, mean value, standard deviation, skewness, kurtosis, maximum frequency component, Zero Crossing Rate, mean and variance of continuous wavelet transform and correlation between each pairwise of accelerometer axis. 
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						The proposed technique is described by three main steps. Firstly we get the raw data from accelerometer and then convert it into usable csv format, separating the coordinates by column. Second step is to extract the above mentioned features taking a window size of 10. Third step is to feed the data in classification algorithms to classify the given activities. 
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						The rest of the description follows the following organisation: Section 2 describes the detailed approach followed to extract feature out of the given dataset. Section 3 shows our classification results and the data set used for verifying. In section 4, we summarised the result.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					We filtered the data and then extracted the features. We plotted the features, grouping three of the features at once. The RED colour represents Standing, GREEN represents Running and BLACK represents Cycling. We took a window size of 10. First we found out the featues for each of the x, y and z coordinates and then took the root mean square of the values.
					<br />1. Mean =  The sum of the sampled values divided by the number of items in the sample.
					<br />2. STD = A quantity expressing by how much the members of a group differ from the mean value for the group.
					<br />3. CoV = Measure of relative variability. It is the ratio of the standard deviation to the mean (average).
					<br />Plotting Mean, STD and CoV:
					<img src="13.png" width="560px" height="420px" alt="This text displays when the image is unavailable"/>
					<br />4. CF = The ratio of peak value to rms value of a window of dataset.
					<br />5. Average = The mean of the magnitues of the net acceleration.
					<br />6. SS25 = Squared sum of data below 25 percentile.
					<br />Plotting CF, Average and SS25:
					<img src="46.png" width="560px" height="420px" alt="This text displays when the image is unavailable"/>
					<br />7. SS75 = Squared sum of data below 75 percentile.
					<br />8. Sum5Hz = Sum of height of frequency component below 5 Hz.
					<br />9. maxFreq = Maximum frequency in spectrum.
					<br />Plotting SS75, sum5Hz, maxFreq
					<img src="79.png" width="560px" height="420px" alt="This text displays when the image is unavailable"/>
					<br />10. LOA = Lag-one AutoCorrelation.
					<br />11. Skew = Measure of symmetry, or more precisely, the lack of symmetry.
					<br />12. Kurt = Measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution.
					<br />Plotting LOA, Skew, Kurt
					<img src="1012.png" width="560px" height="420px" alt="This text displays when the image is unavailable"/>
					<br />13. ZCR = Rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to negative or back.
					<br />Continuous wavelet transform (CWT) analyze how the frequency content of a signal changes over time. If input is real-valued, wt is a 2-D matrix where each row corresponds to one scale. The column size of wt is equal to the length of input. The minimum and maximum scales are determined automatically based on the wavelet's energy spread in frequency and time.
					<br />14. CWTmean = Mean of the mean (2D matrix) of CWT 
					<br />15. CWTvar = Mean of the variance of CWT.
					<br />Plotting ZCR, cwtmean, cwtvar
					<img src="1315.png" width="560px" height="420px" alt="This text displays when the image is unavailable"/>
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						Since, we couldn't get any datset from any source, we recorded it on our own. Initially, we recorded for a total of 2700 samples (1350 seconds, 2 samples per second) for each of our three activities, Running, Cycling and Standing. We extracted the features and found out that the accuracy was quite good. I verified the classification by again recording another set of samples, 600 samples for Running, 800 for Standing and 790 for Cycling. Yet again we got good accuracy on our new dataset.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						We did the initial training of the dataset with train ratio equal to 0.7. After testing the data on the 3/10 of the initial dataset, we tested the same classifier on our second dataset. After that, we merged both the datasets and then trained another classifier to train with train ratio 0.7. The accuracy remained about same for all the three cases.
						The results for each of the classifier is given:
						<img src="RESULT.png" width="460px" height="472px" alt="This text displays when the image is unavailable"/>
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						We classified the accelerometer data with quite a decent accuracy. The accuracy was cross checked with a new dataset and the accuracy remained approximately constant. This gave us the idea that the extracted features were able to be distinguished for the above activities, and thus gave high accuracy.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						The above work has been done only for running, standing and cycling. This project can be extended over classification of all normal day to day activities such as climbing, sleeping, walking, sitting etc. This would help us survey our daily routine and thus make proper improvements.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
